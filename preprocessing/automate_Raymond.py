# -*- coding: utf-8 -*-
"""automate_Raymond.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CpZDgCcn4FtL4SZ-rpc6GBqpyhiZcHeJ
"""

import pandas as pd
import os

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer


def preprocess_data(
    input_path: str,
    output_dir: str,
    target_column: str = "default payment next month"
):
    # Load dataset
    df = pd.read_excel(input_path)

    # Drop duplicates
    df = df.drop_duplicates()

    # Split feature & target
    X = df.drop(columns=[target_column])
    y = df[target_column]

    # Train test split
    X_train, X_test, y_train, y_test = train_test_split(
        X,
        y,
        test_size=0.2,
        random_state=42,
        stratify=y
    )

    # Imputation
    imputer = SimpleImputer(strategy="median")
    X_train = imputer.fit_transform(X_train)
    X_test = imputer.transform(X_test)

    # Scaling
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    # Convert to DataFrame
    X_train_df = pd.DataFrame(X_train, columns=X.columns)
    X_test_df = pd.DataFrame(X_test, columns=X.columns)

    train_df = X_train_df.copy()
    train_df[target_column] = y_train.values

    test_df = X_test_df.copy()
    test_df[target_column] = y_test.values

    # Create output dir
    os.makedirs(output_dir, exist_ok=True)

    train_df.to_csv(
        os.path.join(output_dir, "train_preprocessed.csv"),
        index=False
    )
    test_df.to_csv(
        os.path.join(output_dir, "test_preprocessed.csv"),
        index=False
    )

    print("âœ… Preprocessing selesai. Dataset siap dilatih.")


if __name__ == "__main__":
    preprocess_data(
        input_path="dataset_raw/default of credit card clients.xls",
        output_dir="preprocessing/dataset_preprocessed"
    )
